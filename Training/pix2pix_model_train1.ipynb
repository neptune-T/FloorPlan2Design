{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_images_dir = '../Dataset/A'  # 黑色轮廓图所在的目录\n",
    "color_images_dir = '../Dataset/B'  # 彩色照片所在的目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新数据集类\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class FloorPlanDataset(Dataset):\n",
    "    def __init__(self, black_images_dir, color_images_dir, transform=None):\n",
    "        self.black_images_dir = black_images_dir\n",
    "        self.color_images_dir = color_images_dir\n",
    "        self.transform = transform\n",
    "        self.black_images = sorted(os.listdir(black_images_dir))\n",
    "        self.color_images = sorted(os.listdir(color_images_dir))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.black_images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        black_image_path = os.path.join(self.black_images_dir, self.black_images[idx])\n",
    "        color_image_path = os.path.join(self.color_images_dir, self.color_images[idx])\n",
    "        \n",
    "        black_image = Image.open(black_image_path).convert('RGB')\n",
    "        color_image = Image.open(color_image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            black_image = self.transform(black_image)\n",
    "            color_image = self.transform(color_image)\n",
    "        \n",
    "        return black_image, color_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像预处理\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # 调整图像大小到256x256\n",
    "    transforms.ToTensor(),          # 将图像转换为张量\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化数据加载器\n",
    "\n",
    "# 初始化数据集\n",
    "dataset = FloorPlanDataset(\n",
    "    black_images_dir=black_images_dir,\n",
    "    color_images_dir=color_images_dir,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 初始化数据加载器\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证数据加载器\n",
    "\n",
    "# 获取一个批次的数据\n",
    "for black_images, color_images in dataloader:\n",
    "    print(black_images.shape)  # 预期输出: [batch_size, 3, 256, 256]\n",
    "    print(color_images.shape)  # 预期输出: [batch_size, 3, 256, 256]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成器\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(input_nc, ngf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(ngf, ngf * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(ngf * 2, ngf * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(ngf * 4, ngf * 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, output_nc, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# 初始化生成器\n",
    "generator = Generator(input_nc=3, output_nc=3)\n",
    "print(generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判别器\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(input_nc, ndf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# 初始化判别器\n",
    "discriminator = Discriminator(input_nc=6)  # 3 channels for the black image and 3 for the color image\n",
    "print(discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# 判别器的损失函数\n",
    "criterion_GAN = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 生成器的L1损失，用于生成图像与目标图像之间的像素差异\n",
    "criterion_L1 = nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# 为生成器和判别器分别定义优化器\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查是否有可用的GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 将模型移动到设备上\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 打印 PyTorch 版本\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# 检查 CUDA 是否可用\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# 打印 PyTorch 检测到的 CUDA 版本\n",
    "print(\"CUDA version (reported by PyTorch):\", torch.version.cuda)\n",
    "\n",
    "# 如果 CUDA 可用，打印设备名称\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No CUDA devices detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行判别器前向传播，定义 output_real 和 output_fake\n",
    "output_real = discriminator(real_input)\n",
    "output_fake = discriminator(fake_input)\n",
    "\n",
    "# 定义标签\n",
    "real_labels = torch.ones_like(output_real)\n",
    "fake_labels = torch.zeros_like(output_fake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判别器的损失\n",
    "loss_D_real = criterion_GAN(output_real, real_labels)\n",
    "loss_D_fake = criterion_GAN(output_fake, fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设你有一个目录专门用来保存生成的图片\n",
    "output_dir = 'Training/generated_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (black_images, color_images) in enumerate(dataloader):\n",
    "        black_images = black_images.to(device)\n",
    "        color_images = color_images.to(device)\n",
    "\n",
    "        # 生成器前向传播\n",
    "        fake_images = generator(black_images)\n",
    "\n",
    "        # 更新判别器网络\n",
    "        real_input = torch.cat((black_images, color_images), dim=1)\n",
    "        fake_input = torch.cat((black_images, fake_images.detach()), dim=1)\n",
    "        \n",
    "        output_real = discriminator(real_input)\n",
    "        output_fake = discriminator(fake_input)\n",
    "\n",
    "        real_labels = torch.ones_like(output_real)\n",
    "        fake_labels = torch.zeros_like(output_fake)\n",
    "\n",
    "        loss_D_real = criterion_GAN(output_real, real_labels)\n",
    "        loss_D_fake = criterion_GAN(output_fake, fake_labels)\n",
    "        loss_D = (loss_D_real + loss_D_fake) / 2\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # 更新生成器网络\n",
    "        output_fake = discriminator(fake_input)\n",
    "        loss_G_GAN = criterion_GAN(output_fake, real_labels)\n",
    "        loss_G_L1 = criterion_L1(fake_images, color_images)\n",
    "        loss_G = loss_G_GAN + 100 * loss_G_L1\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # 每个批次打印一次损失\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], \"\n",
    "              f\"Loss_D: {loss_D.item():.4f}, Loss_G: {loss_G.item():.4f}\")\n",
    "\n",
    "    # 在每个epoch结束时保存生成的图片\n",
    "    vutils.save_image(fake_images, os.path.join(output_dir, f\"epoch_{epoch+1}.png\"), normalize=True)\n",
    "    print(f\"Saved generated images for epoch {epoch+1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "archigan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
