{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载器的定义\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class FloorPlanDataset(Dataset):\n",
    "    def __init__(self, black_images_dir, color_images_dir, transform=None):\n",
    "        self.black_images_dir = black_images_dir\n",
    "        self.color_images_dir = color_images_dir\n",
    "        self.transform = transform\n",
    "        self.black_images = sorted(os.listdir(black_images_dir))\n",
    "        self.color_images = sorted(os.listdir(color_images_dir))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.black_images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        black_image_path = os.path.join(self.black_images_dir, self.black_images[idx])\n",
    "        color_image_path = os.path.join(self.color_images_dir, self.color_images[idx])\n",
    "        \n",
    "        black_image = Image.open(black_image_path).convert('RGB')\n",
    "        color_image = Image.open(color_image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            black_image = self.transform(black_image)\n",
    "            color_image = self.transform(color_image)\n",
    "        \n",
    "        return black_image, color_image\n",
    "\n",
    "# 定义数据增强或变换\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # 调整图像大小\n",
    "    transforms.ToTensor()           # 转换为张量\n",
    "])\n",
    "\n",
    "# 初始化数据集和数据加载器\n",
    "black_images_dir = '../Dataset/A'  # 黑色轮廓图所在的目录\n",
    "color_images_dir = '../Dataset/B'  # 彩色照片所在的目录\n",
    "\n",
    "dataset = FloorPlanDataset(black_images_dir, color_images_dir, transform)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成器\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(input_nc, ngf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(ngf, ngf * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(ngf * 2, ngf * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(ngf * 4, ngf * 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, output_nc, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# 初始化生成器\n",
    "generator = Generator(input_nc=3, output_nc=3).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义判别器\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(input_nc, ndf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# 初始化判别器\n",
    "discriminator = Discriminator(input_nc=6).to(device)  # 3 channels for black images + 3 channels for color images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "# 定义GAN损失函数\n",
    "criterion_GAN = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 定义L1损失，用于生成图像与目标图像之间的像素差异\n",
    "criterion_L1 = torch.nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器\n",
    "# 定义生成器和判别器的优化器\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定输出路径\n",
    "output_dir = 'generated_images/2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练设置\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (black_images, color_images) in enumerate(dataloader):\n",
    "        # 将数据移动到设备\n",
    "        black_images = black_images.to(device)\n",
    "        color_images = color_images.to(device)\n",
    "\n",
    "        # ---------------------------\n",
    "        # 训练判别器\n",
    "        # ---------------------------\n",
    "        fake_images = generator(black_images)\n",
    "        real_input = torch.cat((black_images, color_images), dim=1)\n",
    "        fake_input = torch.cat((black_images, fake_images.detach()), dim=1)\n",
    "\n",
    "        output_real = discriminator(real_input)\n",
    "        output_fake = discriminator(fake_input)\n",
    "\n",
    "        real_labels = torch.ones_like(output_real).to(device)\n",
    "        fake_labels = torch.zeros_like(output_fake).to(device)\n",
    "\n",
    "        loss_D_real = criterion_GAN(output_real, real_labels)\n",
    "        loss_D_fake = criterion_GAN(output_fake, fake_labels)\n",
    "        loss_D = (loss_D_real + loss_D_fake) / 2\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # ---------------------------\n",
    "        # 训练生成器\n",
    "        # ---------------------------\n",
    "        output_fake = discriminator(fake_input)\n",
    "        loss_G_GAN = criterion_GAN(output_fake, real_labels)\n",
    "        loss_G_L1 = criterion_L1(fake_images, color_images)\n",
    "        loss_G = loss_G_GAN + 100 * loss_G_L1\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # 每个批次打印一次损失\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], \"\n",
    "              f\"Loss_D: {loss_D.item():.4f}, Loss_G: {loss_G.item():.4f}\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # 保存拼接后的图像\n",
    "    # ---------------------------\n",
    "    with torch.no_grad():\n",
    "        fake_images = generator(black_images)\n",
    "        combined_output = torch.cat((black_images, fake_images), dim=3)\n",
    "\n",
    "        # 保存图像到指定目录\n",
    "        vutils.save_image(combined_output, os.path.join(output_dir, f\"epoch_{epoch+1}.png\"), normalize=True)\n",
    "        print(f\"Saved combined images for epoch {epoch+1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "archigan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
